- Generate architecure using an LLM. Pass it thorugh a mixture of experts and get them to review it. They should be able to point out flaws, and make sure that the system starts from a good plan, found this: https://gwern.net/ai-daydreaming
- can i train a model locally using my data (from emails, whatsapp, etc), just training it to talk like me, think like me. 
- can we train an agent to work by working with us, like we train someone to do something. giving the agent teh access to browser and all, but us telling it what to click and what to do. Agent can ask us questions along the way,, and then we can see the agent mimicking out actions. 
- can we extract the whatsapp chat history, put it through some analysis model, and get insights, charts, etc into a relationship?
- live ai voice changer - tried one middleware to make voice deeper, next step would be to make it Ai generated
- multiple ais, but each with a different role. one ai to coordinate, smaller ais to work. projects can have sages, poc, mvp, cleanup, making it apppear faster, polishes, etc. 
- explore openai app sdk and agentic payment platform in chatgpt 
- did a whatsapp analysis of 2.5 years of relationship chats. Figured out lots of patters. had to switch to key based encryptio, crypt15, and decoded with a custom tool found on github. was able to see the db and export the tables. one interesting thing would be to take all of my text, just my text and analyse it with gemini. FIgure out trends in my thining and ideologies accross time. 
- what the f are vector embeddings? how do they differ from normal ones. why csnt we do any arithmetic on them, why are two embeddings always so close. why do most people not feel the effect (because of top k selections)? are there bidirectional embeddings? if there were, ehat could be done with them? #learn
- checkout https://github.com/neuphonic for tts models on device #tolearn
- Lean the ins-outs of mcp in depth, also this: https://blog.cloudflare.com/code-mode/
- agents that can be hired for very specific tasks by anyone, on a per use basis. ex. a BDE hiring a research agent for 50 rs oer report to get an amazing ppt for an upcoming meet, a data scientist hiring an agent for data cleaning and analysis. maybe multiple people can bet their agents, bid for the cotract, show report, and the user can pick one from the pool 
- liar agent, that lies about the thing it's teaching you to confuse you. you have to figure out the lie, and why is it wrong. it gives almost plausible explaations. liek leaves are green because sunlight yellow + sky blue = green
- what if we fine tune an llm on reddit like qa pairs, realistic conversations, back and forth messages. would it learn how to respond in a more human way. would it become more natural sounding 
- what if we expose an llm to a rag, not connect it, but give it to it as a tool, and then put it in a best answer loop. It can increase decrease the search window, run raw queries(read only) and figure out where to find the answer, just as a human would. Would it outperform traditional rag systems? it would also know it's own context window, and could scale the tokens accordingly, send stuff in two chunks, leave messages for itself. this leave essage for itself can also be expanded. llms communicating with themselves between calls. building their own context. - rlm paper, really interesting, need to explore this further, https://alexzhang13.github.io/blog/2025/rlm/
- Try to make a adapter layer from a raw dataset. let an llm, interspect the raw dataset on a loop usin uvx, figure out the tables, what they mean, how they can be connected, and then come up with intetesting adapter layers that can answer complex queries on the db. Or to write a middleware that can itself execute the queries. like a mcp/tool. 

